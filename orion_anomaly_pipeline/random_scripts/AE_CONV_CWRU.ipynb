{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2493d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 11:57:10.564885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-30 11:57:10.657845: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-30 11:57:10.686284: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-30 11:57:11.041862: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lunet/cosoc/anaconda3/lib/:/home/lunet/cosoc/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/lunet/cosoc/anaconda3/envs/anomaly_AE/lib/:/home/lunet/cosoc/anaconda3/envs/anomaly_AE/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/lunet/cosoc/anaconda3/envs/anomaly_AE/lib/:/home/lunet/cosoc/anaconda3/envs/anomaly_AE/lib/python3.9/site-packages/nvidia/cudnn/lib\n",
      "2023-06-30 11:57:11.041921: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lunet/cosoc/anaconda3/lib/:/home/lunet/cosoc/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/lunet/cosoc/anaconda3/envs/anomaly_AE/lib/:/home/lunet/cosoc/anaconda3/envs/anomaly_AE/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/lunet/cosoc/anaconda3/envs/anomaly_AE/lib/:/home/lunet/cosoc/anaconda3/envs/anomaly_AE/lib/python3.9/site-packages/nvidia/cudnn/lib\n",
      "2023-06-30 11:57:11.041924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify train and test params\n",
    "train_task = 0\n",
    "test_task = 0\n",
    "#specify the data with a certain samplign frequency\n",
    "sample_freq = \"12k\"\n",
    "#specify location where fault is found\n",
    "fault_location = \"DE\"\n",
    "dataset = \"CWRU\"\n",
    "#specify sensor to train on\n",
    "sensor = \"DE\"\n",
    "#set experiment name\n",
    "experiment = \"CWRU_test\"\n",
    "#set path where all folders to run code are\n",
    "base_path = \"/home/lunet/cosoc/Desktop/orion_anomaly_pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the data\n",
    "def get_data(mode, fault_type=\"\"):\n",
    "    if mode == \"train\":\n",
    "        task = \"normal_\" + str(train_task)\n",
    "        path = os.path.join(base_path, \"datasets\", dataset, mode, task, sensor) + \".csv\"\n",
    "        data = pd.read_csv(path, index_col=\"timestamp\")\n",
    "    \n",
    "    elif mode == \"test\":\n",
    "        if fault_type == \"normal\":\n",
    "            task = \"normal_\" + str(train_task)\n",
    "            path = os.path.join(base_path, \"datasets\", dataset, mode, task, sensor) + \".csv\"\n",
    "            data = pd.read_csv(path, index_col=\"timestamp\")\n",
    "        else:\n",
    "            fault = fault_type + \"_\" + str(test_task)\n",
    "            path = os.path.join(base_path, \"datasets\", dataset, mode, sample_freq, fault_location, fault, sensor) + \".csv\"\n",
    "            data = pd.read_csv(path, index_col=\"timestamp\")\n",
    "    \n",
    "    return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb776015",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(mode=\"train\")\n",
    "test_data = get_data(mode=\"test\", fault_type=\"IR028\")\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d67556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise 1 rotation of normal data usef\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(train_data[\"value\"][0:2000])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise 1 rotation of test data used for testing\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(test_data[\"value\"][0:401])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ceb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and save the mean and std we get,\n",
    "# for normalizing test data.\n",
    "training_mean = train_data.mean()\n",
    "training_std = train_data.std()\n",
    "df_training_value = (train_data - training_mean) / training_std\n",
    "print(\"Number of training samples:\", len(df_training_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head())\n",
    "print(df_training_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(values, time_steps=400):\n",
    "    # Generates a widows of length time_steps of a sequence\n",
    "\n",
    "    output = [] \n",
    "    i = 0\n",
    "    while i <= len(values) - time_steps:\n",
    "        output.append(values[i: (i + time_steps)])\n",
    "        i += 1\n",
    "    return np.stack(output)\n",
    "\n",
    "\n",
    "x_train = create_sequences(df_training_value.values)\n",
    "print(\"Training input shape: \", x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ff9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,1,400)\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "#         layers.Conv1D(\n",
    "#             filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "#         ),\n",
    "#         layers.Dropout(rate=0.2),\n",
    "#         layers.Conv1D(\n",
    "#             filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "#         ),\n",
    "#         layers.Conv1DTranspose(\n",
    "#             filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "#         ),\n",
    "#         layers.Dropout(rate=0.2),\n",
    "#         layers.Conv1DTranspose(\n",
    "#             filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "#         ),\n",
    "#         layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "#     ]\n",
    "# )\n",
    "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "\n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(8),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(x_train.shape[2]),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f76793",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d10ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ca515",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55419f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_pred = model.predict(x_train)\n",
    "\n",
    "x_train = x_train.reshape(-1,400,1)\n",
    "x_train_pred = x_train_pred.reshape(-1,400,1)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
    "\n",
    "plt.hist(train_mae_loss, bins=50)\n",
    "plt.xlabel(\"Train MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Get reconstruction loss threshold.\n",
    "threshold = np.max(train_mae_loss)\n",
    "print(\"Reconstruction error threshold: \", threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the first sequence is learnt\n",
    "plt.plot(x_train[0], color='red')\n",
    "plt.plot(x_train_pred[0], color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_value = (test_data - training_mean) / training_std\n",
    "fig, ax = plt.subplots()\n",
    "df_test_value[0:400].plot(legend=False, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Create sequences from test values.\n",
    "x_test = create_sequences(df_test_value.values[0:3000])\n",
    "print(\"Test input shape: \", x_test.shape)\n",
    "\n",
    "# Get test MAE loss.\n",
    "x_test=x_test.reshape(-1,1,400)\n",
    "x_test_pred = model.predict(x_test)\n",
    "print(x_test_pred.shape)\n",
    "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
    "print(np.mean(np.abs(x_test_pred[0]- x_test[0])))\n",
    "test_mae_loss = test_mae_loss.reshape((-1))\n",
    "plt.hist(test_mae_loss, bins=50)\n",
    "plt.xlabel(\"test MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "x_test = x_test.reshape(-1,400,1)\n",
    "x_test_pred = x_test_pred.reshape(-1,400,1)\n",
    "plt.plot(x_test[0], color='red')\n",
    "plt.plot(x_train_pred[0], color='black')\n",
    "plt.show()\n",
    "\n",
    "# Detect all the samples which are anomalies.\n",
    "anomalies = test_mae_loss > threshold\n",
    "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
    "print(\"Indices of anomaly samples: \", np.where(anomalies))\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data i is an anomaly if samples [(i - timesteps + 1) to (i)] are anomalies\n",
    "anomalous_data_indices = []\n",
    "for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):\n",
    "    if np.all(anomalies[data_idx - TIME_STEPS + 1 : data_idx + 1]):\n",
    "        anomalous_data_indices.append(data_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = test_data.iloc[anomalous_data_indices]\n",
    "fig, ax = plt.subplots()\n",
    "test_data.plot(legend=False, ax=ax)\n",
    "df_subset.plot(legend=False, ax=ax, color=\"red\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the first sequence is learnt\n",
    "plt.plot(x_test[0])\n",
    "plt.plot(x_test_pred[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
