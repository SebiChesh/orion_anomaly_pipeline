{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4590f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c044bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'/home/lunet/cosoc/Desktop/orion_anomaly_pipeline'\n",
    "dataset = \"CWRU\"\n",
    "split = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = pd.read_csv(os.path.join(base_path, \"datasets_unprocessed\", dataset, \"labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e912bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_dir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except FileExistsError:\n",
    "        # directory already exists\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456234b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process normal data for train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = file_labels.loc[file_labels[\"fault\"] == \"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in normal_data.iterrows():\n",
    "    new_dir_train = os.path.join(base_path, \"datasets\", dataset, \"train\", row[\"label\"])\n",
    "    new_dir_test = os.path.join(base_path, \"datasets\", dataset, \"test\", row[\"label\"])\n",
    "    mk_dir(new_dir_train)\n",
    "    mk_dir(new_dir_test)\n",
    "    matfile = loadmat(os.path.join(base_path, \"datasets_unprocessed\", dataset, str(row[\"file_name\"]) + \".mat\"))\n",
    "    for i in matfile.keys():\n",
    "        if \"DE\" in i.split(\"_\"):\n",
    "            file_name = \"DE.csv\"\n",
    "            data = matfile.get(i)\n",
    "            index_split = math.ceil((len(data))*split)\n",
    "            train_data = pd.DataFrame({\"timestamp\": list(range(0,index_split,1)) , \"value\": list(data[0:index_split].flatten())})\n",
    "            test_data = pd.DataFrame({\"timestamp\": list(range(index_split, len(data), 1)) , \"value\": list(data[index_split:].flatten())})\n",
    "            train_data.to_csv(path_or_buf= os.path.join(new_dir_train, file_name), index=False)\n",
    "            test_data.to_csv(path_or_buf=os.path.join(new_dir_test, file_name), index=False)\n",
    "            \n",
    "        elif \"FE\" in i.split(\"_\"):\n",
    "            file_name = \"FE.csv\"\n",
    "            data = matfile.get(i)\n",
    "            index_split = math.ceil((len(data))*split)\n",
    "            train_data = pd.DataFrame({\"timestamp\": list(range(0,index_split,1)) , \"value\": list(data[0:index_split].flatten())})\n",
    "            test_data = pd.DataFrame({\"timestamp\": list(range(index_split, len(data), 1)) , \"value\": list(data[index_split:].flatten())})\n",
    "            train_data.to_csv(path_or_buf= os.path.join(new_dir_train, file_name), index=False)\n",
    "            test_data.to_csv(path_or_buf=os.path.join(new_dir_test, file_name), index=False)        \n",
    "        \n",
    "        elif \"BA\" in i.split(\"_\"):\n",
    "            file_name = \"BA.csv\"\n",
    "            data = matfile.get(i)\n",
    "            index_split = math.ceil((len(data))*split)\n",
    "            train_data = pd.DataFrame({\"timestamp\": list(range(0,index_split,1)) , \"value\": list(data[0:index_split].flatten())})\n",
    "            test_data = pd.DataFrame({\"timestamp\": list(range(index_split, len(data), 1)) , \"value\": list(data[index_split:].flatten())})\n",
    "            train_data.to_csv(path_or_buf= os.path.join(new_dir_train, file_name), index=False)\n",
    "            test_data.to_csv(path_or_buf=os.path.join(new_dir_test, file_name), index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process fault data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabde305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 12k and 48k sample freq folder\n",
    "hfreq_path = os.path.join(base_path, \"datasets\", dataset, \"test\", \"48k\")\n",
    "lfreq_path = os.path.join(base_path, \"datasets\", dataset, \"test\", \"12k\")\n",
    "mk_dir(hfreq_path)\n",
    "mk_dir(lfreq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_data = file_labels.loc[file_labels[\"fault\"] != \"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde17eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in fault_data.iterrows():\n",
    "    if row[\"sample_freq\"] == 12 and row[\"fault_location\"] == \"DE\":\n",
    "        directory = os.path.join(lfreq_path, \"DE\")\n",
    "        \n",
    "    elif row[\"sample_freq\"] == 12 and row[\"fault_location\"] == \"FE\":\n",
    "        directory = os.path.join(lfreq_path, \"FE\")\n",
    "            \n",
    "    elif row[\"sample_freq\"] == 48:\n",
    "        directory = os.path.join(hfreq_path, \"DE\")\n",
    "    \n",
    "    else:\n",
    "        print(row)\n",
    "    \n",
    "    matfile = loadmat(os.path.join(base_path, \"datasets_unprocessed\", dataset, str(row[\"file_name\"]) + \".mat\"))\n",
    "    \n",
    "    for i in matfile.keys():\n",
    "        if \"DE\" in i.split(\"_\"):\n",
    "            file_name = \"DE.csv\"\n",
    "            save_path = os.path.join(directory, row[\"label\"])\n",
    "            mk_dir(save_path)\n",
    "            data = matfile.get(i)\n",
    "            df = pd.DataFrame({\"timestamp\": list(range(0, len(data), 1)) , \"value\": list(data.flatten())})\n",
    "            df.to_csv(path_or_buf=os.path.join(save_path, file_name), index=False)   \n",
    "            \n",
    "        elif \"FE\" in i.split(\"_\"):\n",
    "            file_name = \"FE.csv\"\n",
    "            save_path = os.path.join(directory, row[\"label\"])\n",
    "            mk_dir(save_path)\n",
    "            data = matfile.get(i)\n",
    "            df = pd.DataFrame({\"timestamp\": list(range(0, len(data), 1)) , \"value\": list(data.flatten())})\n",
    "            df.to_csv(path_or_buf=os.path.join(save_path, file_name), index=False)\n",
    "            \n",
    "        elif \"BA\" in i.split(\"_\"):\n",
    "            file_name = \"BA.csv\"\n",
    "            save_path = os.path.join(directory, row[\"label\"])\n",
    "            mk_dir(save_path)\n",
    "            data = matfile.get(i)\n",
    "            df = pd.DataFrame({\"timestamp\": list(range(0, len(data), 1)) , \"value\": list(data.flatten())})\n",
    "            df.to_csv(path_or_buf=os.path.join(save_path, file_name), index=False)        \n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8529868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a620fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = \"/home/lunet/cosoc/Desktop/orion_anomaly_pipeline/datasets_unprocessed/PU/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e803e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matfile = loadmat(os.path.join(path_to_dataset, \"KA08\", \"N15_M01_F10_KA08_2.mat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1230cd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35468df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = matfile[\"N15_M01_F10_KA08_2\"][0][0][\"Y\"][\"Data\"][0][-1][0]\n",
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e64d76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0.6\n",
    "index_split = math.ceil((data.size) * split)\n",
    "index_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba43cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({\"timestamp\": list(range(0, data.size)) , \"value\": list(data[:].flatten())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4dc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(\n",
    "    {\"timestamp\": list(range(0, index_split)), \"value\": list(data[0:index_split].flatten())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28b57a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(data[0:index_split].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93195c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(range(0, index_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d60e761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.619507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.170898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.082397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.042725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.021362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153595</th>\n",
       "      <td>153595</td>\n",
       "      <td>-0.006104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153596</th>\n",
       "      <td>153596</td>\n",
       "      <td>-0.048828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153597</th>\n",
       "      <td>153597</td>\n",
       "      <td>-0.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153598</th>\n",
       "      <td>153598</td>\n",
       "      <td>0.006104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153599</th>\n",
       "      <td>153599</td>\n",
       "      <td>-0.027466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp     value\n",
       "0               0 -0.619507\n",
       "1               1  0.170898\n",
       "2               2  0.082397\n",
       "3               3  0.042725\n",
       "4               4 -0.021362\n",
       "...           ...       ...\n",
       "153595     153595 -0.006104\n",
       "153596     153596 -0.048828\n",
       "153597     153597 -0.097656\n",
       "153598     153598  0.006104\n",
       "153599     153599 -0.027466\n",
       "\n",
       "[153600 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d74673e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153601"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e68671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0488281249677312"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e10b5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/home/lunet/cosoc/Desktop/orion_anomaly_pipeline/datasets_unprocessed/PU/labels.csv\")\n",
    "normal_name = \"normal_\" + str(0)\n",
    "test_list = labels.loc[labels[\"label\"] == normal_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39cee0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>fault_location</th>\n",
       "      <th>fault_diameter</th>\n",
       "      <th>motor_load</th>\n",
       "      <th>rpm</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N15_M07_F10_K001_1</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N15_M07_F10_K001_2</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N15_M07_F10_K001_3</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N15_M07_F10_K001_4</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N15_M07_F10_K001_5</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>N15_M07_F10_K006_16</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>N15_M07_F10_K006_17</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>N15_M07_F10_K006_18</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>N15_M07_F10_K006_19</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>N15_M07_F10_K006_20</td>\n",
       "      <td>normal_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>64</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               file_name     label  fault_location  fault_diameter  \\\n",
       "0     N15_M07_F10_K001_1  normal_0             NaN             NaN   \n",
       "1     N15_M07_F10_K001_2  normal_0             NaN             NaN   \n",
       "2     N15_M07_F10_K001_3  normal_0             NaN             NaN   \n",
       "3     N15_M07_F10_K001_4  normal_0             NaN             NaN   \n",
       "4     N15_M07_F10_K001_5  normal_0             NaN             NaN   \n",
       "..                   ...       ...             ...             ...   \n",
       "415  N15_M07_F10_K006_16  normal_0             NaN             NaN   \n",
       "416  N15_M07_F10_K006_17  normal_0             NaN             NaN   \n",
       "417  N15_M07_F10_K006_18  normal_0             NaN             NaN   \n",
       "418  N15_M07_F10_K006_19  normal_0             NaN             NaN   \n",
       "419  N15_M07_F10_K006_20  normal_0             NaN             NaN   \n",
       "\n",
       "     motor_load   rpm  sample_freq   fault  \n",
       "0             0  1500           64  normal  \n",
       "1             0  1500           64  normal  \n",
       "2             0  1500           64  normal  \n",
       "3             0  1500           64  normal  \n",
       "4             0  1500           64  normal  \n",
       "..          ...   ...          ...     ...  \n",
       "415           0  1500           64  normal  \n",
       "416           0  1500           64  normal  \n",
       "417           0  1500           64  normal  \n",
       "418           0  1500           64  normal  \n",
       "419           0  1500           64  normal  \n",
       "\n",
       "[120 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad06bfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307202"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
