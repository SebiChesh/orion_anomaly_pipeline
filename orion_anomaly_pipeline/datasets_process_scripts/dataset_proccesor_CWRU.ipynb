{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4590f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c044bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'/home/lunet/cosoc/Desktop/orion_anomaly_pipeline'\n",
    "dataset = \"CWRU\"\n",
    "split = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09f24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = pd.read_csv(os.path.join(base_path, \"datasets_unprocessed\", dataset, \"labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e912bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_dir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except FileExistsError:\n",
    "        # directory already exists\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456234b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process normal data for train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5e47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = file_labels.loc[file_labels[\"fault\"] == \"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3255d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in normal_data.iterrows():\n",
    "    new_dir_train = os.path.join(base_path, \"datasets\", dataset, \"train\", row[\"label\"])\n",
    "    new_dir_test = os.path.join(base_path, \"datasets\", dataset, \"test\", row[\"label\"])\n",
    "    mk_dir(new_dir_train)\n",
    "    mk_dir(new_dir_test)\n",
    "    matfile = loadmat(os.path.join(base_path, \"datasets_unprocessed\", dataset, str(row[\"file_name\"]) + \".mat\"))\n",
    "    for i in matfile.keys():\n",
    "        if \"DE\" in i.split(\"_\"):\n",
    "            file_name = \"DE.csv\"\n",
    "            data = matfile.get(i)\n",
    "            index_split = math.ceil((len(data))*split)\n",
    "            train_data = pd.DataFrame({\"timestamp\": list(range(0,index_split,1)) , \"value\": list(data[0:index_split].flatten())})\n",
    "            test_data = pd.DataFrame({\"timestamp\": list(range(index_split, len(data), 1)) , \"value\": list(data[index_split:].flatten())})\n",
    "            train_data.to_csv(path_or_buf= os.path.join(new_dir_train, file_name), index=False)\n",
    "            test_data.to_csv(path_or_buf=os.path.join(new_dir_test, file_name), index=False)\n",
    "            \n",
    "        elif \"FE\" in i.split(\"_\"):\n",
    "            file_name = \"FE.csv\"\n",
    "            data = matfile.get(i)\n",
    "            index_split = math.ceil((len(data))*split)\n",
    "            train_data = pd.DataFrame({\"timestamp\": list(range(0,index_split,1)) , \"value\": list(data[0:index_split].flatten())})\n",
    "            test_data = pd.DataFrame({\"timestamp\": list(range(index_split, len(data), 1)) , \"value\": list(data[index_split:].flatten())})\n",
    "            train_data.to_csv(path_or_buf= os.path.join(new_dir_train, file_name), index=False)\n",
    "            test_data.to_csv(path_or_buf=os.path.join(new_dir_test, file_name), index=False)        \n",
    "        \n",
    "        elif \"BA\" in i.split(\"_\"):\n",
    "            file_name = \"BA.csv\"\n",
    "            data = matfile.get(i)\n",
    "            index_split = math.ceil((len(data))*split)\n",
    "            train_data = pd.DataFrame({\"timestamp\": list(range(0,index_split,1)) , \"value\": list(data[0:index_split].flatten())})\n",
    "            test_data = pd.DataFrame({\"timestamp\": list(range(index_split, len(data), 1)) , \"value\": list(data[index_split:].flatten())})\n",
    "            train_data.to_csv(path_or_buf= os.path.join(new_dir_train, file_name), index=False)\n",
    "            test_data.to_csv(path_or_buf=os.path.join(new_dir_test, file_name), index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ad800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process fault data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aabde305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 12k and 48k sample freq folder\n",
    "hfreq_path = os.path.join(base_path, \"datasets\", dataset, \"test\", \"48k\")\n",
    "lfreq_path = os.path.join(base_path, \"datasets\", dataset, \"test\", \"12k\")\n",
    "mk_dir(hfreq_path)\n",
    "mk_dir(lfreq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce7eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_data = file_labels.loc[file_labels[\"fault\"] != \"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bde17eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in fault_data.iterrows():\n",
    "    if row[\"sample_freq\"] == 12 and row[\"fault_location\"] == \"DE\":\n",
    "        directory = os.path.join(lfreq_path, \"DE\")\n",
    "        \n",
    "    elif row[\"sample_freq\"] == 12 and row[\"fault_location\"] == \"FE\":\n",
    "        directory = os.path.join(lfreq_path, \"FE\")\n",
    "            \n",
    "    elif row[\"sample_freq\"] == 48:\n",
    "        directory = os.path.join(hfreq_path, \"DE\")\n",
    "    \n",
    "    else:\n",
    "        print(row)\n",
    "    \n",
    "    matfile = loadmat(os.path.join(base_path, \"datasets_unprocessed\", dataset, str(row[\"file_name\"]) + \".mat\"))\n",
    "    \n",
    "    for i in matfile.keys():\n",
    "        if \"DE\" in i.split(\"_\"):\n",
    "            file_name = \"DE.csv\"\n",
    "            save_path = os.path.join(directory, row[\"label\"])\n",
    "            mk_dir(save_path)\n",
    "            data = matfile.get(i)\n",
    "            df = pd.DataFrame({\"timestamp\": list(range(0, len(data), 1)) , \"value\": list(data.flatten())})\n",
    "            df.to_csv(path_or_buf=os.path.join(save_path, file_name), index=False)   \n",
    "            \n",
    "        elif \"FE\" in i.split(\"_\"):\n",
    "            file_name = \"FE.csv\"\n",
    "            save_path = os.path.join(directory, row[\"label\"])\n",
    "            mk_dir(save_path)\n",
    "            data = matfile.get(i)\n",
    "            df = pd.DataFrame({\"timestamp\": list(range(0, len(data), 1)) , \"value\": list(data.flatten())})\n",
    "            df.to_csv(path_or_buf=os.path.join(save_path, file_name), index=False)\n",
    "            \n",
    "        elif \"BA\" in i.split(\"_\"):\n",
    "            file_name = \"BA.csv\"\n",
    "            save_path = os.path.join(directory, row[\"label\"])\n",
    "            mk_dir(save_path)\n",
    "            data = matfile.get(i)\n",
    "            df = pd.DataFrame({\"timestamp\": list(range(0, len(data), 1)) , \"value\": list(data.flatten())})\n",
    "            df.to_csv(path_or_buf=os.path.join(save_path, file_name), index=False)        \n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
