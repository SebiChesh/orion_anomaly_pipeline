{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd88b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion.data import load_signal, load_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from utils import plot, plot_ts, plot_rws, plot_error, unroll_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = 'nyc_taxi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_signal(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36458aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground truth anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c42d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_anomalies = load_anomalies(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50090cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(known_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'][0]-df['timestamp'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9140e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, known_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c171dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_segments_aggregate(X, interval, time_column, method=['mean']):\n",
    "    \"\"\"Aggregate values over given time span.\n",
    "    Args:\n",
    "        X (ndarray or pandas.DataFrame):\n",
    "            N-dimensional sequence of values.\n",
    "        interval (int):\n",
    "            Integer denoting time span to compute aggregation of.\n",
    "        time_column (int):\n",
    "            Column of X that contains time values.\n",
    "        method (str or list):\n",
    "            Optional. String describing aggregation method or list of strings describing multiple\n",
    "            aggregation methods. If not given, `mean` is used.\n",
    "    Returns:\n",
    "        ndarray, ndarray:\n",
    "            * Sequence of aggregated values, one column for each aggregation method.\n",
    "            * Sequence of index values (first index of each aggregated segment).\n",
    "    \"\"\"\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "    X = X.sort_values(time_column).set_index(time_column)\n",
    "\n",
    "    if isinstance(method, str):\n",
    "        method = [method]\n",
    "\n",
    "    start_ts = X.index.values[0]\n",
    "    max_ts = X.index.values[-1]\n",
    "\n",
    "    values = list()\n",
    "    index = list()\n",
    "    while start_ts <= max_ts:\n",
    "        end_ts = start_ts + interval\n",
    "        subset = X.loc[start_ts:end_ts - 1]\n",
    "        aggregated = [\n",
    "            getattr(subset, agg)(skipna=True).values\n",
    "            for agg in method\n",
    "        ]\n",
    "        values.append(np.concatenate(aggregated))\n",
    "        index.append(start_ts)\n",
    "        start_ts = end_ts\n",
    "\n",
    "    return np.asarray(values), np.asarray(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, index = time_segments_aggregate(df, interval=1800, time_column='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b68736",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer()\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d08ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig = X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce82f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e0a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_sequences(X, index, window_size, target_size, step_size, target_column,\n",
    "                             drop=None, drop_windows=False):\n",
    "    \"\"\"Create rolling window sequences out of time series data.\n",
    "    The function creates an array of input sequences and an array of target sequences by rolling\n",
    "    over the input sequence with a specified window.\n",
    "    Optionally, certain values can be dropped from the sequences.\n",
    "    Args:\n",
    "        X (ndarray):\n",
    "            N-dimensional sequence to iterate over.\n",
    "        index (ndarray):\n",
    "            Array containing the index values of X.\n",
    "        window_size (int):\n",
    "            Length of the input sequences.\n",
    "        target_size (int):\n",
    "            Length of the target sequences SEBI: I BELIEVE THIS IS THE VALUE WHICH IT WILL PREDICT FROM SEEING A SEQUENCE I.E IF TARGET_SIZE = 1 AND IT SEES 0-100 VALUES, IT WILL TRY AND PREDICT 101 AND IF TARGET_SIZE = 2 IT WILL PREDICT 101 AND 102. y IS JUST THE LIST OF ALL VALUES THE MODEL WILL PREDICT\n",
    "        step_size (int):\n",
    "            Indicating the number of steps to move the window forward each round.\n",
    "        target_column (int):\n",
    "            Indicating which column of X is the target.\n",
    "        drop (ndarray or None or str or float or bool):\n",
    "            Optional. Array of boolean values indicating which values of X are invalid, or value\n",
    "            indicating which value should be dropped. If not given, `None` is used.\n",
    "        drop_windows (bool):\n",
    "            Optional. Indicates whether the dropping functionality should be enabled. If not\n",
    "            given, `False` is used.\n",
    "    Returns:\n",
    "        ndarray, ndarray, ndarray, ndarray:\n",
    "            * input sequences.\n",
    "            * target sequences.\n",
    "            * first index value of each input sequence.\n",
    "            * first index value of each target sequence.\n",
    "    \"\"\"\n",
    "    out_X = list()\n",
    "    out_y = list()\n",
    "    X_index = list()\n",
    "    y_index = list()\n",
    "    target = X[:, target_column]\n",
    "\n",
    "    if drop_windows:\n",
    "        if hasattr(drop, '__len__') and (not isinstance(drop, str)):\n",
    "            if len(drop) != len(X):\n",
    "                raise Exception('Arrays `drop` and `X` must be of the same length.')\n",
    "        else:\n",
    "            if isinstance(drop, float) and np.isnan(drop):\n",
    "                drop = np.isnan(X)\n",
    "            else:\n",
    "                drop = X == drop\n",
    "\n",
    "    start = 0\n",
    "    max_start = len(X) - window_size - target_size + 1\n",
    "    while start < max_start:\n",
    "        end = start + window_size\n",
    "\n",
    "        if drop_windows:\n",
    "            drop_window = drop[start:end + target_size]\n",
    "            to_drop = np.where(drop_window)[0]\n",
    "            if to_drop.size:\n",
    "                start += to_drop[-1] + 1\n",
    "                continue\n",
    "\n",
    "        out_X.append(X[start:end])\n",
    "        out_y.append(target[end:end + target_size])\n",
    "        X_index.append(index[start])\n",
    "        y_index.append(index[end])\n",
    "        start = start + step_size\n",
    "\n",
    "    return np.asarray(out_X), np.asarray(out_y), np.asarray(X_index), np.asarray(y_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c176408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_index, y_index = rolling_window_sequences(X, index, \n",
    "                                                  window_size=100, \n",
    "                                                  target_size=1, \n",
    "                                                  step_size=1,\n",
    "                                                  target_column=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c73c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data input shape: {}\".format(X.shape))\n",
    "print(\"Training data index shape: {}\".format(X_index.shape))\n",
    "print(\"Training y shape: {}\".format(y.shape))\n",
    "print(\"Training y index shape: {}\".format(y_index.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import hyperparameters\n",
    "from orion.primitives.tadgan import TadGAN\n",
    "\n",
    "hyperparameters[\"epochs\"] = 5\n",
    "hyperparameters[\"input_shape\"] = (100, 1) # based on the window size\n",
    "hyperparameters[\"optimizer\"] = \"keras.optimizers.Adam\"\n",
    "hyperparameters[\"learning_rate\"] = 0.0005\n",
    "hyperparameters[\"latent_dim\"] = 20\n",
    "hyperparameters[\"batch_size\"] = 64\n",
    "\n",
    "tgan = TadGAN(**hyperparameters)\n",
    "tgan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30779e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "X_hat, critic = tgan.predict(X)\n",
    "\n",
    "# visualize X_hat\n",
    "plot_rws(X_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e01fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# flatten the predicted windows\n",
    "y_hat = unroll_ts(X_hat)\n",
    "\n",
    "# plot the time series\n",
    "plot_ts([y, y_hat], labels=['original', 'reconstructed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fc2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [*range(0, len(y))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496de295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of original\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "\n",
    "ax.plot(x, y, linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of reconstructed\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "\n",
    "ax.plot(x, y_hat, linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that the GAN model did really well in trying to reconstruct the signal. We also see how it expected the signal to be, in comparison to what it actually is. The discrepancies between the two signals will be used to calculate the error. The higher the error, the more likely it is an anomaly\n",
    "\n",
    "# pair-wise error calculation\n",
    "error = np.zeros(shape=y.shape)\n",
    "length = y.shape[0]\n",
    "for i in range(length):\n",
    "    error[i] = abs(y_hat[i] - y[i])\n",
    "\n",
    "# visualize the error curve\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "plt.plot(error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb053fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from orion.primitives.tadgan import score_anomalies\n",
    "\n",
    "error_area, true_index, true, pred = score_anomalies(X, X_hat, critic, X_index, rec_error_type=\"area\", comb=\"mult\")\n",
    "pred = np.array(pred).mean(axis=2)\n",
    "\n",
    "# visualize the error curve\n",
    "plot_error([[true, pred], error_area])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_point, true_index, true, pred = score_anomalies(X, X_hat, critic, X_index, rec_error_type=\"point\", comb=\"mult\")\n",
    "pred = np.array(pred).mean(axis=2)\n",
    "\n",
    "# visualize the error curve\n",
    "plot_error([[true, pred], error_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6042208",
   "metadata": {},
   "outputs": [],
   "source": [
    "error, true_index, true, pred = score_anomalies(X, X_hat, critic, X_index, rec_error_type=\"dtw\", comb=\"mult\")\n",
    "pred = np.array(pred).mean(axis=2)\n",
    "\n",
    "# visualize the error curve\n",
    "plot_error([[true, pred], error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed threshold\n",
    "thresh = 6\n",
    "\n",
    "intervals = list()\n",
    "\n",
    "i = 0\n",
    "max_start = len(error)\n",
    "while i < max_start:\n",
    "    j = i\n",
    "    start = index[i]\n",
    "    while i < len(error) and error[i] > thresh:\n",
    "        i += 1\n",
    "    \n",
    "    end = index[i]\n",
    "    if start != end:\n",
    "        intervals.append((start, end, np.mean(error[j: i+1])))\n",
    "        \n",
    "    i += 1\n",
    "        \n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = pd.DataFrame(intervals, columns=['start', 'end', 'score'])\n",
    "plot(df, [anomalies, known_anomalies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a window to look at segment of error values and taking into account the mean and stdev of the errors in that window\n",
    "from orion.primitives.timeseries_anomalies import find_anomalies\n",
    "\n",
    "# find anomalies\n",
    "intervals = find_anomalies(error, index, \n",
    "                           window_size_portion=0.3, \n",
    "                           window_step_size_portion=0.05, \n",
    "                           fixed_threshold=True)\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# visualize the result\n",
    "anomalies = pd.DataFrame(intervals, columns=['start', 'end', 'score'])\n",
    "plot(df, [anomalies, known_anomalies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_signal = 'S-1-new'\n",
    "new_data = load_signal(new_signal)\n",
    "ground_truth = load_anomalies('S-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398ac66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50dba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = orion.detect(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
